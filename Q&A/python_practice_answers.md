# Python ì‹¤ë¬´ ì—°ìŠµë¬¸ì œ - ë‹µì•ˆ

> âš ï¸ **ì£¼ì˜**: ë¨¼ì € ìŠ¤ìŠ¤ë¡œ ë¬¸ì œë¥¼ í’€ì–´ë³´ê³ , ë§‰í ë•Œë§Œ ì°¸ê³ í•˜ì„¸ìš”!

---

## Section 1: ë¹ŒíŠ¸ì¸ ëª¨ë“ˆ ë‹µì•ˆ

### ë¬¸ì œ 1-1: í•™ìƒ ì„±ì  í•„í„°ë§ (JSON)

```python
import json

# JSON íŒŒì¼ ì½ê¸°
with open('students.json', 'r', encoding='utf-8') as f:
    students = json.load(f)

# í‰ê·  ê³„ì‚° ë° í•„í„°ë§
high_scorers = []
total_avg = 0

for student in students:
    avg = (student['math'] + student['english'] + student['science']) / 3
    student['average'] = round(avg, 2)  # í‰ê·  ì¶”ê°€
    
    if avg >= 80:
        high_scorers.append(student)
    
    total_avg += avg

# ì „ì²´ í‰ê·  ê³„ì‚°
overall_avg = total_avg / len(students)

# ê²°ê³¼ ì €ì¥
with open('high_scores.json', 'w', encoding='utf-8') as f:
    json.dump(high_scorers, f, ensure_ascii=False, indent=2)

# ì¶œë ¥
print(f"ê³ ë“ì  í•™ìƒ ìˆ˜: {len(high_scorers)}ëª…")
print(f"ì „ì²´ í‰ê· : {overall_avg:.2f}ì ")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
ê³ ë“ì  í•™ìƒ ìˆ˜: 4ëª…
ì „ì²´ í‰ê· : 83.42ì 
```

---

### ë¬¸ì œ 1-2: ë§¤ì¶œ ë°ì´í„° ë¶„ì„ (CSV)

```python
import csv
from collections import defaultdict

# CSV ì½ê¸° ë° ë§¤ì¶œ ì§‘ê³„
sales_by_product = defaultdict(int)

with open('sales.csv', 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        product = row['product']
        price = int(row['price'])
        quantity = int(row['quantity'])
        total = price * quantity
        sales_by_product[product] += total

# ë§¤ì¶œì•¡ ìˆœìœ¼ë¡œ ì •ë ¬
sorted_sales = sorted(sales_by_product.items(), key=lambda x: x[1], reverse=True)

# ìƒìœ„ 3ê°œ ì¶”ì¶œ
top_3 = sorted_sales[:3]

# CSVë¡œ ì €ì¥
with open('top_products.csv', 'w', encoding='utf-8', newline='') as f:
    writer = csv.DictWriter(f, fieldnames=['product', 'total_sales'])
    writer.writeheader()
    for product, sales in top_3:
        writer.writerow({'product': product, 'total_sales': sales})

# ì „ì²´ ë§¤ì¶œì•¡
total_sales = sum(sales_by_product.values())

print(f"ì „ì²´ ë§¤ì¶œì•¡: {total_sales:,}ì›")
print("ìƒìœ„ ì œí’ˆì´ top_products.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ìƒìœ„ ì œí’ˆ ì¶œë ¥
print("\n=== ë§¤ì¶œ ìƒìœ„ 3ê°œ ì œí’ˆ ===")
for rank, (product, sales) in enumerate(top_3, 1):
    print(f"{rank}. {product}: {sales:,}ì›")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
ì „ì²´ ë§¤ì¶œì•¡: 21,025,000ì›
ìƒìœ„ ì œí’ˆì´ top_products.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.

=== ë§¤ì¶œ ìƒìœ„ 3ê°œ ì œí’ˆ ===
1. ë…¸íŠ¸ë¶: 14,400,000ì›
2. ëª¨ë‹ˆí„°: 5,850,000ì›
3. íƒœë¸”ë¦¿: 3,900,000ì›
```

---

### ë¬¸ì œ 1-3: ë‹¤ê°€ì˜¤ëŠ” ì´ë²¤íŠ¸ ì°¾ê¸° (datetime)

```python
import json
from datetime import datetime, timedelta

# ì˜¤ëŠ˜ ë‚ ì§œ
today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
week_later = today + timedelta(days=7)

# JSON ì½ê¸°
with open('events.json', 'r', encoding='utf-8') as f:
    events = json.load(f)

# 7ì¼ ì´ë‚´ ì´ë²¤íŠ¸ í•„í„°ë§
upcoming_events = []

for event in events:
    event_date = datetime.strptime(event['date'], '%Y-%m-%d')
    
    # ì˜¤ëŠ˜ë¶€í„° 7ì¼ ì´ë‚´ì¸ì§€ í™•ì¸
    if today <= event_date <= week_later:
        # D-Day ê³„ì‚°
        days_diff = (event_date - today).days
        
        if days_diff == 0:
            d_day = "D-Day"
        elif days_diff > 0:
            d_day = f"D-{days_diff}"
        else:
            d_day = f"D+{abs(days_diff)}"
        
        event['d_day'] = d_day
        event['days_until'] = days_diff
        upcoming_events.append(event)

# D-Day ìˆœìœ¼ë¡œ ì •ë ¬ (ê°€ê¹Œìš´ ìˆœ)
upcoming_events.sort(key=lambda x: x['days_until'])

# days_until í•„ë“œëŠ” ì •ë ¬ìš©ì´ë¯€ë¡œ ì œê±°
for event in upcoming_events:
    del event['days_until']

# ì €ì¥
with open('upcoming_events.json', 'w', encoding='utf-8') as f:
    json.dump(upcoming_events, f, ensure_ascii=False, indent=2)

print(f"7ì¼ ì´ë‚´ ì´ë²¤íŠ¸: {len(upcoming_events)}ê°œ")
print("upcoming_events.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n")

print("=== ë‹¤ê°€ì˜¤ëŠ” ì´ë²¤íŠ¸ ===")
for event in upcoming_events:
    print(f"{event['d_day']} - {event['title']} ({event['date']})")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
7ì¼ ì´ë‚´ ì´ë²¤íŠ¸: 5ê°œ
upcoming_events.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.

=== ë‹¤ê°€ì˜¤ëŠ” ì´ë²¤íŠ¸ ===
D-Day - ì„±ê³¼ í‰ê°€ (2026-01-13)
D-1 - ê³ ê° ë¯¸íŒ… (2026-01-14)
D-2 - í”„ë¡œì íŠ¸ ë§ˆê° (2026-01-15)
D-3 - êµìœ¡ ì„¸ë¯¸ë‚˜ (2026-01-16)
D-5 - íŒ€ íšŒì‹ (2026-01-18)
```

---

### ë¬¸ì œ 1-4: ë¡œê·¸ íŒŒì¼ ë¶„ì„ (ì •ê·œí‘œí˜„ì‹)

```python
import re
import json
from collections import Counter

# ë¡œê·¸ íŒŒì¼ ì½ê¸°
with open('server_log.txt', 'r', encoding='utf-8') as f:
    log_content = f.read()

# IP ì£¼ì†Œ íŒ¨í„´ (xxx.xxx.xxx.xxx)
ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'

# ëª¨ë“  IP ì£¼ì†Œ ì°¾ê¸°
ip_addresses = re.findall(ip_pattern, log_content)

# IPë³„ ì¹´ìš´íŠ¸
ip_counts = dict(Counter(ip_addresses))

# ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ
error_pattern = r'\[ERROR\]\s+(.+?)(?:\s+from|$)'
errors = re.findall(error_pattern, log_content)

# ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
result = {
    "ip_counts": ip_counts,
    "errors": errors
}

# JSON ì €ì¥
with open('log_analysis.json', 'w', encoding='utf-8') as f:
    json.dump(result, f, ensure_ascii=False, indent=2)

print("=== ë¡œê·¸ ë¶„ì„ ê²°ê³¼ ===")
print(f"\nì´ ê³ ìœ  IP ìˆ˜: {len(ip_counts)}")
print("\nIPë³„ ì ‘ì† íšŸìˆ˜:")
for ip, count in sorted(ip_counts.items(), key=lambda x: x[1], reverse=True):
    print(f"  {ip}: {count}íšŒ")

print(f"\nì´ ì—ëŸ¬ ìˆ˜: {len(errors)}")
print("\nì—ëŸ¬ ë©”ì‹œì§€:")
for i, error in enumerate(errors, 1):
    print(f"  {i}. {error}")

print("\nlog_analysis.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
=== ë¡œê·¸ ë¶„ì„ ê²°ê³¼ ===

ì´ ê³ ìœ  IP ìˆ˜: 6

IPë³„ ì ‘ì† íšŸìˆ˜:
  192.168.1.105: 4íšŒ
  10.0.0.23: 4íšŒ
  192.168.1.1: 3íšŒ
  172.16.0.8: 3íšŒ
  10.0.0.45: 2íšŒ
  172.16.0.15: 1íšŒ

ì´ ì—ëŸ¬ ìˆ˜: 5

ì—ëŸ¬ ë©”ì‹œì§€:
  1. Connection timeout
  2. Database connection failed
  3. Invalid authentication token
  4. File not found: /images/product.jpg
  5. Memory limit exceeded on server

log_analysis.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
```

---

### ë¬¸ì œ 1-5: íŒŒì¼ ì •ë¦¬ ë„êµ¬ (pathlib)

```python
import json
from pathlib import Path

# ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
file_stats = {}

# data í´ë”ì˜ ëª¨ë“  .txt íŒŒì¼ ì°¾ê¸°
data_dir = Path('data')

if not data_dir.exists():
    print("data í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    txt_files = list(data_dir.glob('*.txt'))
    
    for file_path in txt_files:
        # íŒŒì¼ ì½ê¸°
        content = file_path.read_text(encoding='utf-8')
        
        # ë‹¨ì–´ ìˆ˜ ê³„ì‚° (ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬)
        words = content.split()
        word_count = len(words)
        
        # íŒŒì¼ í¬ê¸° (ë°”ì´íŠ¸)
        size_bytes = file_path.stat().st_size
        
        # ê²°ê³¼ ì €ì¥ (ìƒëŒ€ ê²½ë¡œë¡œ)
        relative_path = str(file_path)
        file_stats[relative_path] = {
            "word_count": word_count,
            "size_bytes": size_bytes
        }
    
    # JSON ì €ì¥
    with open('file_stats.json', 'w', encoding='utf-8') as f:
        json.dump(file_stats, f, ensure_ascii=False, indent=2)
    
    print("=== íŒŒì¼ í†µê³„ ===")
    print(f"\në¶„ì„í•œ íŒŒì¼ ìˆ˜: {len(file_stats)}\n")
    
    for file_path, stats in file_stats.items():
        print(f"{file_path}")
        print(f"  - ë‹¨ì–´ ìˆ˜: {stats['word_count']:,}ê°œ")
        print(f"  - íŒŒì¼ í¬ê¸°: {stats['size_bytes']:,} bytes\n")
    
    print("file_stats.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
=== íŒŒì¼ í†µê³„ ===

ë¶„ì„í•œ íŒŒì¼ ìˆ˜: 3

data/file1.txt
  - ë‹¨ì–´ ìˆ˜: 23ê°œ
  - íŒŒì¼ í¬ê¸°: 294 bytes

data/file2.txt
  - ë‹¨ì–´ ìˆ˜: 30ê°œ
  - íŒŒì¼ í¬ê¸°: 399 bytes

data/file3.txt
  - ë‹¨ì–´ ìˆ˜: 25ê°œ
  - íŒŒì¼ í¬ê¸°: 325 bytes

file_stats.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
```

---

## Section 2: ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹µì•ˆ

### ë¬¸ì œ 2-1: ê³µê³µ API í™œìš© (requests)

```python
import requests
import json

# 1. ëª¨ë“  ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
users_url = 'https://jsonplaceholder.typicode.com/users'
response = requests.get(users_url)

if response.status_code == 200:
    users = response.json()
    print(f"ì´ {len(users)}ëª…ì˜ ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\n")
    
    # 2. ê° ì‚¬ìš©ìì˜ ê²Œì‹œê¸€ ìˆ˜ ì¡°íšŒ
    user_posts_stats = []
    
    for user in users:
        user_id = user['id']
        name = user['name']
        email = user['email']
        
        # í•´ë‹¹ ì‚¬ìš©ìì˜ ê²Œì‹œê¸€ ê°€ì ¸ì˜¤ê¸°
        posts_url = f'https://jsonplaceholder.typicode.com/posts?userId={user_id}'
        posts_response = requests.get(posts_url)
        
        if posts_response.status_code == 200:
            posts = posts_response.json()
            post_count = len(posts)
            
            # ë°ì´í„° í•©ì¹˜ê¸°
            user_stat = {
                "id": user_id,
                "name": name,
                "email": email,
                "post_count": post_count
            }
            user_posts_stats.append(user_stat)
            
            print(f"âœ“ {name}: {post_count}ê°œì˜ ê²Œì‹œê¸€")
    
    # 3. JSON ì €ì¥
    with open('user_posts_stats.json', 'w', encoding='utf-8') as f:
        json.dump(user_posts_stats, f, ensure_ascii=False, indent=2)
    
    print(f"\nuser_posts_stats.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
ì´ 10ëª…ì˜ ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.

âœ“ Leanne Graham: 10ê°œì˜ ê²Œì‹œê¸€
âœ“ Ervin Howell: 10ê°œì˜ ê²Œì‹œê¸€
âœ“ Clementine Bauch: 10ê°œì˜ ê²Œì‹œê¸€
âœ“ Patricia Lebsack: 10ê°œì˜ ê²Œì‹œê¸€
âœ“ Chelsey Dietrich: 10ê°œì˜ ê²Œì‹œê¸€
âœ“ Mrs. Dennis Schulist: 10ê°œì˜ ê²Œì‹œê¸€
âœ“ Kurtis Weissnat: 10ê°œì˜ ê²Œì‹œê¸€
âœ“ Nicholas Runolfsdottir V: 10ê°œì˜ ê²Œì‹œê¸€
âœ“ Glenna Reichert: 10ê°œì˜ ê²Œì‹œê¸€
âœ“ Clementina DuBuque: 10ê°œì˜ ê²Œì‹œê¸€

user_posts_stats.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
```

---

### ë¬¸ì œ 2-2: í™˜ìœ¨ ë°ì´í„° ìˆ˜ì§‘ (requests)

```python
import requests
from datetime import datetime

# API í˜¸ì¶œ
url = 'https://api.exchangerate-api.com/v4/latest/USD'
response = requests.get(url)

if response.status_code == 200:
    data = response.json()
    rates = data['rates']
    
    # í•„ìš”í•œ í†µí™”ë§Œ ì¶”ì¶œ
    currencies = {
        'KRW': 'ì›',
        'JPY': 'ì—”',
        'EUR': 'ìœ ë¡œ',
        'CNY': 'ìœ„ì•ˆ'
    }
    
    # ê²°ê³¼ ë¬¸ìì—´ ìƒì„±
    output_lines = []
    output_lines.append("í™˜ìœ¨ ì •ë³´ (ê¸°ì¤€: USD 1,000)")
    output_lines.append("=" * 30)
    
    for code, unit in currencies.items():
        if code in rates:
            rate = rates[code]
            converted = rate * 1000
            output_lines.append(f"{code}: {converted:,.0f}{unit}")
    
    output_lines.append("=" * 30)
    output_lines.append(f"ì¡°íšŒ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # íŒŒì¼ ì €ì¥
    with open('exchange_rates.txt', 'w', encoding='utf-8') as f:
        f.write('\n'.join(output_lines))
    
    # í™”ë©´ ì¶œë ¥
    print('\n'.join(output_lines))
    print("\nexchange_rates.txtì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
í™˜ìœ¨ ì •ë³´ (ê¸°ì¤€: USD 1,000)
==============================
KRW: 1,320,500ì›
JPY: 147,230ì—”
EUR: 920ìœ ë¡œ
CNY: 7,245ìœ„ì•ˆ
==============================
ì¡°íšŒ ì‹œê°„: 2026-01-13 14:30:25

exchange_rates.txtì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
```

---

### ë¬¸ì œ 2-3: ì§ì› ë°ì´í„° ë¶„ì„ (pandas)

```python
import pandas as pd

# CSV ì½ê¸°
df = pd.read_csv('employees.csv')

print("=== ì§ì› ë°ì´í„° ë¶„ì„ ===\n")

# 1. ë¶€ì„œë³„ í‰ê·  ì—°ë´‰
dept_avg_salary = df.groupby('department')['salary'].mean()
print("1. ë¶€ì„œë³„ í‰ê·  ì—°ë´‰:")
for dept, avg in dept_avg_salary.items():
    print(f"   {dept}: {avg:,.0f}ì›")

# 2. ì¬ì§ê¸°ê°„ 5ë…„ ì´ìƒ í•„í„°ë§
long_term = df[df['years_of_service'] >= 5]
print(f"\n2. ì¬ì§ê¸°ê°„ 5ë…„ ì´ìƒ ì§ì›: {len(long_term)}ëª…")

# 3. ì„±ê³¼í‰ê°€ 'Excellent'ì¸ ì§ì›ì˜ í‰ê·  ì—°ë´‰
excellent_emp = df[df['performance'] == 'Excellent']
excellent_avg = excellent_emp['salary'].mean()
print(f"\n3. ì„±ê³¼í‰ê°€ 'Excellent' ì§ì› í‰ê·  ì—°ë´‰: {excellent_avg:,.0f}ì›")

# 4. ë³´ê³ ì„œ ìƒì„±
salary_report = df.groupby('department').agg({
    'employee_id': 'count',
    'salary': ['mean', 'max', 'min']
}).round(0)

# ì»¬ëŸ¼ëª… ì •ë¦¬
salary_report.columns = ['ì§ì›_ìˆ˜', 'í‰ê· _ì—°ë´‰', 'ìµœê³ _ì—°ë´‰', 'ìµœì €_ì—°ë´‰']
salary_report = salary_report.reset_index()
salary_report.columns = ['ë¶€ì„œëª…', 'ì§ì›_ìˆ˜', 'í‰ê· _ì—°ë´‰', 'ìµœê³ _ì—°ë´‰', 'ìµœì €_ì—°ë´‰']

# CSV ì €ì¥
salary_report.to_csv('salary_report.csv', index=False, encoding='utf-8-sig')

print("\n4. ë¶€ì„œë³„ ì—°ë´‰ ë³´ê³ ì„œ:")
print(salary_report.to_string(index=False))

# ì¶”ê°€ ë„ì „: ê° ë¶€ì„œ ìµœê³  ì—°ë´‰ì
print("\n5. ë¶€ì„œë³„ ìµœê³  ì—°ë´‰ì:")
top_earners = df.loc[df.groupby('department')['salary'].idxmax()]
for _, row in top_earners.iterrows():
    print(f"   {row['department']}: {row['name']} ({row['salary']:,}ì›)")

print("\nsalary_report.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
=== ì§ì› ë°ì´í„° ë¶„ì„ ===

1. ë¶€ì„œë³„ í‰ê·  ì—°ë´‰:
   ê°œë°œ: 75,571,429ì›
   ë§ˆì¼€íŒ…: 60,000,000ì›
   ì˜ì—…: 61,500,000ì›
   ì¸ì‚¬: 52,750,000ì›

2. ì¬ì§ê¸°ê°„ 5ë…„ ì´ìƒ ì§ì›: 11ëª…

3. ì„±ê³¼í‰ê°€ 'Excellent' ì§ì› í‰ê·  ì—°ë´‰: 71,181,818ì›

4. ë¶€ì„œë³„ ì—°ë´‰ ë³´ê³ ì„œ:
 ë¶€ì„œëª…  ì§ì›_ìˆ˜     í‰ê· _ì—°ë´‰     ìµœê³ _ì—°ë´‰     ìµœì €_ì—°ë´‰
   ê°œë°œ       7  75571429.0  88000000.0  66000000.0
 ë§ˆì¼€íŒ…       5  60000000.0  63000000.0  55000000.0
 ì˜ì—…       4  61500000.0  71000000.0  52000000.0
 ì¸ì‚¬       4  52750000.0  57000000.0  48000000.0

5. ë¶€ì„œë³„ ìµœê³  ì—°ë´‰ì:
   ê°œë°œ: ì¥ì„œí˜„ (88,000,000ì›)
   ë§ˆì¼€íŒ…: ê¶Œë‚˜ì˜ (63,000,000ì›)
   ì˜ì—…: ë…¸ì§€í›ˆ (71,000,000ì›)
   ì¸ì‚¬: ë¬¸ì •í˜¸ (57,000,000ì›)

salary_report.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
```

---

### ë¬¸ì œ 2-4: ë³µí•© ë°ì´í„° ë¶„ì„ (pandas)

```python
import pandas as pd

# íŒŒì¼ ì½ê¸°
orders = pd.read_csv('orders.csv')
products = pd.read_csv('products.csv')

print("=== ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ë¶„ì„ ===\n")

# 1. ë°ì´í„° ê²°í•©
merged = pd.merge(orders, products, on='product_id')
print(f"1. ì´ ì£¼ë¬¸ ê±´ìˆ˜: {len(merged)}")

# 2. ì£¼ë¬¸ë³„ ì´ ê¸ˆì•¡ ê³„ì‚°
merged['total_amount'] = merged['quantity'] * merged['price']

# 3. ë‚ ì§œ ë³€í™˜
merged['order_date'] = pd.to_datetime(merged['order_date'])

# 4. 2024ë…„ 1ì›” ë°ì´í„°ë§Œ í•„í„°ë§
jan_2024 = merged[(merged['order_date'].dt.year == 2024) & 
                  (merged['order_date'].dt.month == 1)]

print(f"2. 2024ë…„ 1ì›” ì£¼ë¬¸: {len(jan_2024)}ê±´")
print(f"3. ì´ ë§¤ì¶œì•¡: {jan_2024['total_amount'].sum():,}ì›\n")

# Sheet1: ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ
category_sales = jan_2024.groupby('category').agg({
    'total_amount': 'sum',
    'order_id': 'count',
    'quantity': 'sum'
}).round(0)
category_sales.columns = ['ì´_ë§¤ì¶œì•¡', 'ì£¼ë¬¸_ê±´ìˆ˜', 'íŒë§¤_ìˆ˜ëŸ‰']
category_sales = category_sales.reset_index()
category_sales = category_sales.sort_values('ì´_ë§¤ì¶œì•¡', ascending=False)

print("=== ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ===")
print(category_sales.to_string(index=False))

# Sheet2: ì¼ë³„ ë§¤ì¶œ
daily_sales = jan_2024.groupby('order_date').agg({
    'total_amount': 'sum',
    'order_id': 'count'
}).round(0)
daily_sales.columns = ['ì¼ë³„_ë§¤ì¶œì•¡', 'ì£¼ë¬¸_ê±´ìˆ˜']
daily_sales = daily_sales.reset_index()
daily_sales['order_date'] = daily_sales['order_date'].dt.strftime('%Y-%m-%d')

print("\n=== ì¼ë³„ ë§¤ì¶œ (ì²˜ìŒ 5ì¼) ===")
print(daily_sales.head().to_string(index=False))

# Sheet3: ë² ìŠ¤íŠ¸ ìƒí’ˆ Top 10
product_sales = jan_2024.groupby(['product_id', 'product_name', 'category']).agg({
    'total_amount': 'sum',
    'quantity': 'sum'
}).round(0)
product_sales.columns = ['ì´_ë§¤ì¶œì•¡', 'íŒë§¤_ìˆ˜ëŸ‰']
product_sales = product_sales.reset_index()
product_sales = product_sales.sort_values('ì´_ë§¤ì¶œì•¡', ascending=False).head(10)

print("\n=== ë² ìŠ¤íŠ¸ ìƒí’ˆ Top 10 ===")
print(product_sales.to_string(index=False))

# ì—‘ì…€ ì €ì¥
with pd.ExcelWriter('sales_analysis.xlsx', engine='openpyxl') as writer:
    category_sales.to_excel(writer, sheet_name='ì¹´í…Œê³ ë¦¬ë³„_ë§¤ì¶œ', index=False)
    daily_sales.to_excel(writer, sheet_name='ì¼ë³„_ë§¤ì¶œ', index=False)
    product_sales.to_excel(writer, sheet_name='ë² ìŠ¤íŠ¸ìƒí’ˆ', index=False)

print("\nsales_analysis.xlsxì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
=== ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ë¶„ì„ ===

1. ì´ ì£¼ë¬¸ ê±´ìˆ˜: 30
2. 2024ë…„ 1ì›” ì£¼ë¬¸: 30ê±´
3. ì´ ë§¤ì¶œì•¡: 6,193,000ì›

=== ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ===
  category  ì´_ë§¤ì¶œì•¡  ì£¼ë¬¸_ê±´ìˆ˜  íŒë§¤_ìˆ˜ëŸ‰
  ì „ìê¸°ê¸°  4603000.0       21       44
 ì €ì¥ì¥ì¹˜  1131000.0        6       11
 ì•¡ì„¸ì„œë¦¬   459000.0        3        9

=== ì¼ë³„ ë§¤ì¶œ (ì²˜ìŒ 5ì¼) ===
  order_date  ì¼ë³„_ë§¤ì¶œì•¡  ì£¼ë¬¸_ê±´ìˆ˜
  2024-01-05    450000.0          2
  2024-01-06    267000.0          1
  2024-01-07    125000.0          1
  2024-01-08    270000.0          1
  2024-01-09    140000.0          1

=== ë² ìŠ¤íŠ¸ ìƒí’ˆ Top 10 ===
 product_id       product_name  category  ì´_ë§¤ì¶œì•¡  íŒë§¤_ìˆ˜ëŸ‰
       P003         27ì¸ì¹˜ ëª¨ë‹ˆí„°    ì „ìê¸°ê¸°    760000.0          2
       P010      ì™¸ì¥ SSD 1TB   ì €ì¥ì¥ì¹˜    540000.0          4
       P001         ë¬´ì„  ë§ˆìš°ìŠ¤    ì „ìê¸°ê¸°    315000.0          9
       P006         ë¬´ì„  ì´ì–´í°    ì „ìê¸°ê¸°    534000.0          6
       P002      ê¸°ê³„ì‹ í‚¤ë³´ë“œ    ì „ìê¸°ê¸°    375000.0          3
...

sales_analysis.xlsxì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
```

---

## Section 3: ì¢…í•© í”„ë¡œì íŠ¸ ë‹µì•ˆ

### í”„ë¡œì íŠ¸: ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ íŒŒì´í”„ë¼ì¸

```python
import requests
import pandas as pd
import json
from datetime import datetime
import time

# OMDb API Key (ë¬´ë£Œ ë°œê¸‰: http://www.omdbapi.com/apikey.aspx)
API_KEY = 'YOUR_API_KEY_HERE'  # ì—¬ê¸°ì— ë°œê¸‰ë°›ì€ API í‚¤ ì…ë ¥
BASE_URL = 'http://www.omdbapi.com/'

def fetch_movie_data(title, api_key):
    """ì˜í™” ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    params = {
        'apikey': api_key,
        't': title,
        'type': 'movie'
    }
    
    try:
        response = requests.get(BASE_URL, params=params)
        if response.status_code == 200:
            data = response.json()
            if data.get('Response') == 'True':
                return data
        return None
    except Exception as e:
        print(f"Error fetching {title}: {e}")
        return None

def main():
    start_time = datetime.now()
    print("=" * 50)
    print("ì˜í™” ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œì‘")
    print("=" * 50)
    print(f"ì‹œì‘ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # movies.txt ì½ê¸°
    with open('movies.txt', 'r', encoding='utf-8') as f:
        movie_titles = [line.strip() for line in f if line.strip()]
    
    print(f"ì´ {len(movie_titles)}ê°œ ì˜í™” ê²€ìƒ‰ ì‹œì‘...\n")
    
    # ë°ì´í„° ìˆ˜ì§‘
    movies_data = []
    success_count = 0
    fail_count = 0
    
    for i, title in enumerate(movie_titles, 1):
        print(f"[{i}/{len(movie_titles)}] {title} ê²€ìƒ‰ì¤‘...", end=' ')
        
        data = fetch_movie_data(title, API_KEY)
        
        if data:
            # í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ
            movie_info = {
                'title': data.get('Title'),
                'year': data.get('Year'),
                'rating': data.get('imdbRating'),
                'genre': data.get('Genre'),
                'director': data.get('Director'),
                'runtime': data.get('Runtime')
            }
            movies_data.append(movie_info)
            success_count += 1
            print("âœ“")
        else:
            fail_count += 1
            print("âœ— (ì‹¤íŒ¨)")
        
        # API í˜¸ì¶œ ì œí•œ ë°©ì§€ (ì´ˆë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜ ì œí•œ)
        time.sleep(0.3)
    
    print(f"\nìˆ˜ì§‘ ì™„ë£Œ: ì„±ê³µ {success_count}ê±´, ì‹¤íŒ¨ {fail_count}ê±´\n")
    
    # DataFrame ìƒì„±
    df = pd.DataFrame(movies_data)
    
    # ë°ì´í„° ì •ì œ
    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')
    df['year'] = pd.to_numeric(df['year'], errors='coerce')
    
    # ì¥ë¥´ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬
    df['genres'] = df['genre'].str.split(', ')
    
    # ì›ë³¸ ë°ì´í„° ì €ì¥
    df.to_csv('movies_data.csv', index=False, encoding='utf-8-sig')
    print("âœ“ movies_data.csv ì €ì¥ ì™„ë£Œ")
    
    # ë¶„ì„ ì‹œì‘
    print("\n" + "=" * 50)
    print("ë°ì´í„° ë¶„ì„ ì¤‘...")
    print("=" * 50 + "\n")
    
    analysis_results = {}
    
    # 1. ì—°ë„ë³„ ì˜í™” ìˆ˜
    year_counts = df['year'].value_counts().sort_index()
    analysis_results['movies_by_year'] = year_counts.to_dict()
    
    # 2. ì¥ë¥´ë³„ í‰ê·  í‰ì 
    genre_ratings = {}
    all_genres = df['genres'].explode().unique()
    for genre in all_genres:
        mask = df['genres'].apply(lambda x: genre in x if isinstance(x, list) else False)
        avg_rating = df[mask]['rating'].mean()
        genre_ratings[genre] = round(avg_rating, 2)
    
    analysis_results['average_rating_by_genre'] = genre_ratings
    
    # 3. í‰ì  ìƒìœ„ 10ê°œ
    top_10 = df.nlargest(10, 'rating')[['title', 'year', 'rating', 'director']]
    analysis_results['top_10_movies'] = top_10.to_dict('records')
    
    # 4. ê°ë…ë³„ ì˜í™” ìˆ˜
    director_counts = df['director'].value_counts().head(10)
    analysis_results['movies_by_director'] = director_counts.to_dict()
    
    # JSON ì €ì¥
    with open('movies_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, ensure_ascii=False, indent=2)
    print("âœ“ movies_analysis.json ì €ì¥ ì™„ë£Œ")
    
    # ë³´ê³ ì„œ ìƒì„±
    report_lines = []
    report_lines.append("=" * 60)
    report_lines.append("ì˜í™” ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ")
    report_lines.append("=" * 60)
    report_lines.append(f"\nìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"ë¶„ì„ ì˜í™” ìˆ˜: {len(df)}")
    report_lines.append(f"í‰ê·  í‰ì : {df['rating'].mean():.2f}")
    
    report_lines.append("\n" + "-" * 60)
    report_lines.append("í‰ì  ìƒìœ„ 10ê°œ ì˜í™”")
    report_lines.append("-" * 60)
    for i, movie in enumerate(top_10.itertuples(), 1):
        report_lines.append(f"{i:2d}. {movie.title} ({movie.year}) - {movie.rating}/10")
        report_lines.append(f"    ê°ë…: {movie.director}")
    
    report_lines.append("\n" + "-" * 60)
    report_lines.append("ì¥ë¥´ë³„ í‰ê·  í‰ì ")
    report_lines.append("-" * 60)
    for genre, rating in sorted(genre_ratings.items(), key=lambda x: x[1], reverse=True):
        report_lines.append(f"{genre:20s}: {rating:.2f}/10")
    
    report_lines.append("\n" + "=" * 60)
    
    # ë³´ê³ ì„œ ì €ì¥
    with open('movies_report.txt', 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))
    print("âœ“ movies_report.txt ì €ì¥ ì™„ë£Œ")
    
    # í™”ë©´ì—ë„ ì¶œë ¥
    print("\n" + '\n'.join(report_lines))
    
    # ì‹¤í–‰ ì‹œê°„
    end_time = datetime.now()
    elapsed = (end_time - start_time).total_seconds()
    
    print(f"\nì´ ì‹¤í–‰ ì‹œê°„: {elapsed:.2f}ì´ˆ")
    print("\nëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰")

if __name__ == '__main__':
    main()
```

**ì‹¤í–‰ ì‹œ ì£¼ì˜ì‚¬í•­:**

1. OMDb API í‚¤ ë°œê¸‰ í•„ìš”
   - http://www.omdbapi.com/apikey.aspx ì—ì„œ ë¬´ë£Œ ë°œê¸‰
   - í•˜ë£¨ 1,000íšŒ ìš”ì²­ ì œí•œ

2. ì‹¤í–‰ ë°©ë²•:
   ```bash
   python movie_analysis.py
   ```

3. ìƒì„±ë˜ëŠ” íŒŒì¼:
   - `movies_data.csv`: ì›ë³¸ ë°ì´í„°
   - `movies_analysis.json`: ë¶„ì„ ê²°ê³¼
   - `movies_report.txt`: ë³´ê¸° ì¢‹ì€ ë³´ê³ ì„œ

---

## í•™ìŠµ í¬ì¸íŠ¸ ì •ë¦¬

### Section 1ì—ì„œ ë°°ìš´ ê²ƒë“¤

1. **JSON ì²˜ë¦¬**
   - `json.load()`, `json.dump()` ì‚¬ìš©ë²•
   - ë”•ì…”ë„ˆë¦¬ ì¡°ì‘

2. **CSV ì²˜ë¦¬**
   - `DictReader`, `DictWriter` í™œìš©
   - ë°ì´í„° ì§‘ê³„ (defaultdict í™œìš©)

3. **ë‚ ì§œ/ì‹œê°„**
   - `strptime`, `strftime` ë³€í™˜
   - `timedelta`ë¡œ ë‚ ì§œ ê³„ì‚°

4. **ì •ê·œí‘œí˜„ì‹**
   - `findall`, `search`, `sub` í™œìš©
   - ì‹¤ì „ íŒ¨í„´ ì‘ì„±

5. **íŒŒì¼ ì‹œìŠ¤í…œ**
   - `pathlib` ê°ì²´ ì§€í–¥ ë°©ì‹
   - `glob` íŒ¨í„´ ë§¤ì¹­

### Section 2ì—ì„œ ë°°ìš´ ê²ƒë“¤

1. **HTTP ìš”ì²­**
   - REST API í˜¸ì¶œ
   - JSON ì‘ë‹µ ì²˜ë¦¬

2. **pandas ê¸°ì´ˆ**
   - ë°ì´í„° ì½ê¸°/ì“°ê¸°
   - í•„í„°ë§, ì •ë ¬
   - groupby ì§‘ê³„

3. **pandas ê³ ê¸‰**
   - merge (í…Œì´ë¸” ê²°í•©)
   - ë‚ ì§œ ë°ì´í„° ì²˜ë¦¬
   - ì—‘ì…€ ë‹¤ì¤‘ ì‹œíŠ¸

### ì¢…í•© í”„ë¡œì íŠ¸ì—ì„œ ë°°ìš´ ê²ƒë“¤

- ì‹¤ë¬´ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°
- API í˜¸ì¶œ ì œí•œ ì²˜ë¦¬
- ì—ëŸ¬ í•¸ë“¤ë§
- ì§„í–‰ ìƒí™© í‘œì‹œ
- ë‹¤ì–‘í•œ í¬ë§·ìœ¼ë¡œ ê²°ê³¼ ì €ì¥

---

## ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ

1. **ê°ì²´ ì§€í–¥ í”„ë¡œê·¸ë˜ë° (OOP)**
   - í´ë˜ìŠ¤ì™€ ê°ì²´
   - ìƒì†ê³¼ ë‹¤í˜•ì„±

2. **ê³ ê¸‰ pandas**
   - pivot_table
   - ì‹œê³„ì—´ ë¶„ì„
   - ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ

3. **ë°ì´í„° ì‹œê°í™”**
   - matplotlib, seaborn
   - plotly (ì¸í„°ë™í‹°ë¸Œ)

4. **ë°ì´í„°ë² ì´ìŠ¤**
   - SQL ê¸°ì´ˆ
   - SQLAlchemy

5. **ì›¹ ìŠ¤í¬ë˜í•‘**
   - BeautifulSoup
   - Selenium

---

**ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤! ê³„ì† ì—°ìŠµí•˜ë©´ ì‹¤ë ¥ì´ ì‘¥ì‘¥ ëŠ˜ì–´ë‚  ê±°ì˜ˆìš”! ğŸ’ª**
